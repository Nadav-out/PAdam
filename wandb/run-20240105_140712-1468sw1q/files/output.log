
Training[33m...
Best Validation Accuracy: [1m49.74[22m%, achived at epoch [1m1[22m with [1m0.0[22m% sparsity
Best Validation Loss: [1m1.5178[22m, achived at epoch [1m1[22m with [1m0.0[22m% sparsity
Epoch: [1m1[22m/[1m200[22m    Train Loss: [1m1.5329[22m      Test Loss: [1m1.5178[22m       Accuracy: [1m49.74[22m%        Current LR: [1m0.00005
Epoch: [1m2[22m/[1m200[22m    Train Loss: [1m1.1476[22m      Test Loss: [1m1.8343[22m       Accuracy: [1m48.33[22m%        Current LR: [1m0.00170
Best Validation Accuracy: [1m70.10[22m%, achived at epoch [1m3[22m with [1m0.0[22m% sparsity
Best Validation Loss: [1m0.8499[22m, achived at epoch [1m3[22m with [1m0.0[22m% sparsity
Epoch: [1m3[22m/[1m200[22m    Train Loss: [1m0.9640[22m      Test Loss: [1m0.8499[22m       Accuracy: [1m70.10[22m%        Current LR: [1m0.00335
Best Validation Accuracy: [1m74.29[22m%, achived at epoch [1m4[22m with [1m0.0[22m% sparsity
Best Validation Loss: [1m0.7286[22m, achived at epoch [1m4[22m with [1m0.0[22m% sparsity
Epoch: [1m4[22m/[1m200[22m    Train Loss: [1m0.8044[22m      Test Loss: [1m0.7286[22m       Accuracy: [1m74.29[22m%        Current LR: [1m0.00500
Best Validation Accuracy: [1m75.81[22m%, achived at epoch [1m5[22m with [1m0.0[22m% sparsity
Best Validation Loss: [1m0.7144[22m, achived at epoch [1m5[22m with [1m0.0[22m% sparsity
Epoch: [1m5[22m/[1m200[22m    Train Loss: [1m0.6875[22m      Test Loss: [1m0.7144[22m       Accuracy: [1m75.81[22m%        Current LR: [1m0.00500
Best Validation Accuracy: [1m79.83[22m%, achived at epoch [1m6[22m with [1m0.0[22m% sparsity
Best Validation Loss: [1m0.6089[22m, achived at epoch [1m6[22m with [1m0.0[22m% sparsity
Epoch: [1m6[22m/[1m200[22m    Train Loss: [1m0.6172[22m      Test Loss: [1m0.6089[22m       Accuracy: [1m79.83[22m%        Current LR: [1m0.00500
Epoch: [1m7[22m/[1m200[22m    Train Loss: [1m0.5582[22m      Test Loss: [1m0.6128[22m       Accuracy: [1m79.79[22m%        Current LR: [1m0.00500
Traceback (most recent call last):
  File "./python/train_CIFAR_new.py", line 475, in <module>
    main()
  File "./python/train_CIFAR_new.py", line 376, in main
    avg_train_loss = train_one_epoch(model, trainloader, optimizer, criterion, scheduler, args.grad_clip)
  File "./python/train_CIFAR_new.py", line 109, in train_one_epoch
    loss.backward()
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt