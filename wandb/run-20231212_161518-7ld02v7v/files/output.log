
[2023-12-12 16:15:41,341] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
Reached accuracy 54.71% on epoch 1. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00000
Epoch: 1/100	Train Loss: 1.7863	Test Loss: 1.2887	Accuracy: 54.71%	Current LR: 0.00025	Elapsed Time: 00:01:19	Expected Time: 02:12:53
Reached accuracy 56.93% on epoch 2. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00001
Epoch: 2/100	Train Loss: 1.2151	Test Loss: 1.2854	Accuracy: 56.93%	Current LR: 0.00050	Elapsed Time: 00:01:59	Expected Time: 01:39:23
Reached accuracy 62.66% on epoch 3. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00002
Epoch: 3/100	Train Loss: 0.9964	Test Loss: 1.1541	Accuracy: 62.66%	Current LR: 0.00075	Elapsed Time: 00:02:38	Expected Time: 01:28:13
Reached accuracy 67.37% on epoch 4. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00003
Epoch: 4/100	Train Loss: 0.8607	Test Loss: 0.9725	Accuracy: 67.37%	Current LR: 0.00100	Elapsed Time: 00:03:18	Expected Time: 01:22:43
Reached accuracy 68.46% on epoch 5. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00004
Epoch: 5/100	Train Loss: 0.7487	Test Loss: 0.9785	Accuracy: 68.46%	Current LR: 0.00100	Elapsed Time: 00:03:58	Expected Time: 01:19:21
Reached accuracy 77.11% on epoch 6. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00004
Epoch: 6/100	Train Loss: 0.6540	Test Loss: 0.7119	Accuracy: 77.11%	Current LR: 0.00100	Elapsed Time: 00:04:37	Expected Time: 01:17:12
Reached accuracy 79.90% on epoch 7. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00005

Epoch: 8/100	Train Loss: 0.5392	Test Loss: 0.6489	Accuracy: 78.55%	Current LR: 0.00100	Elapsed Time: 00:05:56	Expected Time: 01:14:13
Reached accuracy 81.36% on epoch 9. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00006
Epoch: 9/100	Train Loss: 0.4813	Test Loss: 0.5776	Accuracy: 81.36%	Current LR: 0.00099	Elapsed Time: 00:06:35	Expected Time: 01:13:18
Reached accuracy 83.69% on epoch 10. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00006

Epoch: 11/100	Train Loss: 0.4216	Test Loss: 0.6291	Accuracy: 79.78%	Current LR: 0.00099	Elapsed Time: 00:07:55	Expected Time: 01:11:58
Reached accuracy 85.61% on epoch 12. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00007
Epoch: 12/100	Train Loss: 0.3955	Test Loss: 0.4222	Accuracy: 85.61%	Current LR: 0.00098	Elapsed Time: 00:08:34	Expected Time: 01:11:30
Reached accuracy 85.77% on epoch 13. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00007
Epoch: 13/100	Train Loss: 0.3623	Test Loss: 0.4356	Accuracy: 85.77%	Current LR: 0.00098	Elapsed Time: 00:09:14	Expected Time: 01:11:06
Reached accuracy 87.00% on epoch 14. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00008



Epoch: 17/100	Train Loss: 0.2881	Test Loss: 0.5246	Accuracy: 84.66%	Current LR: 0.00096	Elapsed Time: 00:11:52	Expected Time: 01:09:48
Reached accuracy 88.79% on epoch 18. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00009


Epoch: 20/100	Train Loss: 0.2426	Test Loss: 0.3760	Accuracy: 88.22%	Current LR: 0.00093	Elapsed Time: 00:13:49	Expected Time: 01:09:08
Reached accuracy 88.96% on epoch 21. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00010
Epoch: 21/100	Train Loss: 0.2301	Test Loss: 0.3553	Accuracy: 88.96%	Current LR: 0.00093	Elapsed Time: 00:14:29	Expected Time: 01:08:59
Reached accuracy 89.86% on epoch 22. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00010




Epoch: 26/100	Train Loss: 0.1764	Test Loss: 0.3591	Accuracy: 88.66%	Current LR: 0.00088	Elapsed Time: 00:17:44	Expected Time: 01:08:14
Reached accuracy 90.28% on epoch 27. Model saved to /global/home/users/njo/PAdam/python/./CIFAR10/p0p8/best_model.pth.
Sparsity: 0.00012
Epoch: 27/100	Train Loss: 0.1626	Test Loss: 0.3050	Accuracy: 90.28%	Current LR: 0.00087	Elapsed Time: 00:18:24	Expected Time: 01:08:12
Traceback (most recent call last):
  File "./python/train_CIFAR.py", line 322, in <module>
    main()
  File "./python/train_CIFAR.py", line 215, in main
    outputs = model(inputs)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 82, in forward
    return self.dynamo_ctx(self._orig_mod.forward)(*args, **kwargs)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/global/home/users/njo/PAdam/python/models.py", line 133, in forward
    def forward(self, xb):
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 2836, in forward
    return compiled_fn(full_args)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 1224, in g
    return f(*args)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 2403, in debug_compiled_function
    return compiled_function(*args)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 1900, in runtime_wrapper
    all_outs = call_func_with_args(
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 1249, in call_func_with_args
    out = normalize_as_list(f(args))
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 1224, in g
    return f(*args)
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 2168, in forward
    fw_outs = call_func_with_args(
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 1249, in call_func_with_args
    out = normalize_as_list(f(args))
  File "/global/home/users/njo/anaconda3/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 248, in run
    return model(new_inputs)
  File "/tmp/torchinductor_njo/vd/cvd6l3sb4coj7p6okqerky4mnwinzvzuseibb7tpkjirgwa3avq6.py", line 1630, in call
    torch.randint(2**31, size=(), dtype=torch.int64, out=seed_cuda_0)
KeyboardInterrupt